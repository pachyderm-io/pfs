# Pipeline Scaling Limitation in Community Edition

!!! Warning "We are here to help!" 
    Scaling Pachyderm pipelines is easy to do but hard for users to perfect. 

It can be difficult to balance the breaking down of data science systems into multiple pipelines, horizontally scaling those pipelines to optimize the processing time and effectively understanding Pachyderm's unique data-first approach to development in connecting those pipelines. Lalalal

Starting with this new 1.13.0 release, we introduce a **limit to the number of pipelines and their parallelization** Community Edition users can deploy.

These limits have been set high enough for most of our users to benefit from Pachyderm Community Edition capabilities while allowing us to **better assist in designing, scaling, and running pipelines** those whose workload and pipeline numbers require finer tuning to handle their workload efficiently.

## Scaling Limitation

Our new limitation have been set on:

- The **number of pipelines** deployed: Community Users can deploy **up to 16 pipelines**.
- The **number of workers** for each pipeline: Community Users can run **up to 8 workers in parallel** on each pipeline.

Our Customer Success Experience has shown us that hitting those limits means that you are likely to be needing our assistance in optimizing your DAGs.

## Lift the limitation

We provide an easy way to request a **2 weeks Enterprise Token** that will help you experiment with Pachyderm without limit. //TODO insert a link to the Request token page here

!!! note "Please know..." 
    Pachyderm offers readily available activation keys for proofs-of-concept, startups, academic, nonprofit, or open-source projects. Tell us about your project, get in touch. //TODO Add link to contact sales

## What happens when you exceed those limits?

As a general rule, each `pachctl` command requiring an enterprise key check (For example: `pachctl auth,` `pachctl deploy ide`...) will generate an alert message in your STDERR with a link to the Enterprise landing page. 

Similarly, all of the `pachctl deploy` commands will generate an alert message in your STDERR and provide a link to request a 14 day trial Enterprise key.

### Pipelines limit

- `pachctl create pipeline` will succeed if creating without upsert, fail when trying to upsert. 

- `pachctl update pipeline`  and and `pachctl edit pipeline` will succeed when not upserting and fail when upserting. 
!!! Note
    If update pipeline fails for any other reason, it does not log any message related to pipeline limits.

- `pachctl restore` fails when trying to restore with too many pipelines. 

In any case, running any of the following commands below will create a distinct message to stderr as well as to the pachd logs and let you know the number of pipelines limit, what number of pipelines you have, and provide a link to request an Enterprise key.

### Workers limit

When trying to create the parallelism too high:

(//TODO investigate which it is fail or succeed... Jd seemed to suggest it should fail - To be validated)

- `pachctl create pipeline` and `pachctl update pipeline` should succeed/fail. A message to stderr and pachd logs is generated.

- `pachctl create, update, edit pipeline` with any coefficient parallelism or [dynamic parallelism](//TODO link to dynamic parallelism section) should succeed/fail, implement the limit, and log error to stderr and pachd logs.

## What happens when you upgrade to 1.13?

!!! Important
    All existing pipelines **continue to work** after an upgrade to 1.13. pachd logs will mention the successful startup above the "update pipeline message".

- `pachctl create pipeline` fails as mentionned in [Pipelines limit](#pipelines-limit) above. 

- `pachctl update pipeline` and `pachctl edit pipeline` continue to work **if not creating a new pipeline** and output the message mentioned above.  

- `pachctl extract, list, run, start, stop pipeline` continue to work as before.

!!! Note
    Pipelines automatically generated by the system (for example, build pipelines, cron...) are not considered when assessing the total number of pipelines. The limit applies to user-created pipelines only. (//TODO link to build pipelines)